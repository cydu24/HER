"""CoSER Benchmark - Given-Circumstance Acting Evaluation

å®Œæ•´å®ç° CoSER è¯„æµ‹æµç¨‹ï¼š
1. å¤šè§’è‰²å¯¹è¯æ¨¡æ‹Ÿ (GCA Simulation)
2. LLM-as-Judge å››ç»´åº¦è¯„ä¼°
3. æ”¯æŒç¼“å­˜å’Œæ–­ç‚¹ç»­ä¼ 
4. æ”¯æŒæ¨ç†å’Œè¯„ä¼°åˆ†ç¦»

æ¨¡å‹ç±»å‹æ”¯æŒï¼š
- coser: CoSER åŸç”Ÿæ ¼å¼ [...] + (...)
- her: HER æ ¼å¼ <role_thinking> + <role_action>
- qwen: Qwen æ ¼å¼ (ChatML)
- llama3: Llama3 æ ¼å¼
- api: æ ‡å‡† API æ ¼å¼ (GPT/Claude/Gemini)
"""

import json
import random
import asyncio
import logging
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

from ..base import (
    MultiTurnBenchmark,
    BenchmarkConfig,
    InferenceResult,
    EvaluationResult,
    CacheManager
)
from .prompts import (
    get_character_prompt,
    get_environment_prompt,
    get_nsp_prompt,
    CRITIC_PROMPTS
)
from .utils import (
    remove_system_thinking,
    parse_nsp_response,
    extract_last_speaker,
    remove_inner_thoughts,
    remove_role_thinking,
    remove_long_role_thinking,
    add_speaker_name,
    calculate_bleu_rouge,
    apply_qwen_chat_template,
    get_model_type,
    get_stop_tokens,
    convert_her_format,
    convert_coser_to_her_format,
    convert_to_coser_format
)

logger = logging.getLogger(__name__)

# ç‰¹æ®Šè§’è‰²
ENVIRONMENT = 'Environment'
NSP = "NSP"
SPECIAL_CHARACTERS = [NSP, ENVIRONMENT]

# å®Œæ•´æ—¥å¿—æ¨¡å¼
FULL_LOG = os.environ.get('FULL_LOG', '0') == '1'

# æ—¥å¿—åˆ†éš”çº¿
LOG_SEP = "=" * 80
LOG_SEP_THIN = "-" * 60


def full_log_print(msg, prefix="ğŸ“‹"):
    """å®Œæ•´æ—¥å¿—æ¨¡å¼ä¸‹æ‰“å°è¯¦ç»†ä¿¡æ¯"""
    if FULL_LOG:
        print(f"{prefix} {msg}")


def detailed_log(title: str, content: str, prefix: str = "ğŸ“‹", max_len: int = None):
    """æ‰“å°è¯¦ç»†çš„ç»“æ„åŒ–æ—¥å¿—"""
    if not FULL_LOG:
        return
    print(f"\n{LOG_SEP_THIN}")
    print(f"{prefix} {title}")
    print(LOG_SEP_THIN)
    if max_len and len(content) > max_len:
        print(f"{content[:max_len]}...\n[æˆªæ–­ï¼Œå…± {len(content)} å­—ç¬¦]")
    else:
        print(content)
    print(LOG_SEP_THIN)


def log_messages(messages: list, title: str = "Messages (ChatTemplate ä¹‹å‰)", truncate: bool = False):
    """æ‰“å° messages åˆ—è¡¨ï¼ˆOpenAI æ ¼å¼ JSONï¼‰
    
    Args:
        messages: OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        title: æ—¥å¿—æ ‡é¢˜
        truncate: æ˜¯å¦æˆªæ–­é•¿å†…å®¹ï¼ˆé»˜è®¤ Falseï¼Œæ‰“å°å®Œæ•´å†…å®¹ï¼‰
    """
    if not FULL_LOG:
        return
    print(f"\n{LOG_SEP}")
    print(f"ğŸ“¨ {title} (å…± {len(messages)} æ¡æ¶ˆæ¯)")
    print(LOG_SEP)
    
    # æ‰“å°å®Œæ•´çš„ JSON æ ¼å¼
    import json
    for i, msg in enumerate(messages):
        role = msg.get('role', 'unknown')
        name = msg.get('name', '')
        content = msg.get('content', '')
        
        # æ„å»ºæ˜¾ç¤ºç”¨çš„æ¶ˆæ¯å¯¹è±¡
        display_msg = {"role": role}
        if name:
            display_msg["name"] = name
        
        # æ ¹æ® truncate å‚æ•°å†³å®šæ˜¯å¦æˆªæ–­
        if truncate and len(content) > 500:
            display_msg["content"] = content[:500] + f"...[æˆªæ–­ï¼Œå…±{len(content)}å­—ç¬¦]"
        else:
            display_msg["content"] = content
        
        print(f"\n[{i}] " + json.dumps(display_msg, ensure_ascii=False, indent=2))
    
    print(f"\n{LOG_SEP}")


def log_messages_json(messages: list, agent_name: str, round_num: int):
    """ä»¥ JSON æ ¼å¼æ‰“å°å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆç”¨äºè°ƒè¯•å¤šè½®å¯¹è¯ï¼‰"""
    if not FULL_LOG:
        return
    import json
    print(f"\n[LOG:MESSAGES] [{agent_name}] ç¬¬ {round_num + 1} è½®")
    print(f"{'ğŸ”·'*30}")
    print(f"ğŸ”· [{agent_name}] ç¬¬ {round_num} è½® - å®Œæ•´æ¶ˆæ¯é˜Ÿåˆ— (å…± {len(messages)} æ¡)")
    print(f"{'ğŸ”·'*30}")
    
    for i, msg in enumerate(messages):
        print(f"\n--- Message [{i}] ---")
        # å®Œæ•´æ‰“å°ï¼Œä¸æˆªæ–­
        formatted = json.dumps(msg, ensure_ascii=False, indent=2)
        print(formatted)
    
    print(f"\n{'ğŸ”·'*30}\n")


@dataclass
class CoSERConfig(BenchmarkConfig):
    """CoSER ä¸“å±é…ç½®"""
    # æ¨¡å‹é…ç½®
    actor_model: str = ""  # è§’è‰²æ‰®æ¼”æ¨¡å‹
    env_model: str = ""    # ç¯å¢ƒæ¨¡å‹
    nsp_model: str = ""    # ä¸‹ä¸€è¯´è¯è€…é¢„æµ‹æ¨¡å‹
    judge_model: str = ""  # è¯„ä¼°æ¨¡å‹
    
    # æ¨¡æ‹Ÿé…ç½®
    max_rounds: int = 10
    continue_from: int = 0  # ä»ç¬¬å‡ è½®å¼€å§‹ç”¨æ¨¡å‹ç”Ÿæˆï¼ˆä¹‹å‰ç”¨ ground truthï¼‰
    wo_thought: bool = False  # æ˜¯å¦ç¦ç”¨å†…å¿ƒæƒ³æ³•
    retrieval: Optional[str] = None  # æ£€ç´¢å¢å¼ºç±»å‹
    nsp_mode: str = "model"  # NSPæ¨¡å¼: "model"=ä½¿ç”¨æ¨¡å‹é¢„æµ‹, "random"=éšæœºé€‰æ‹©è§’è‰²
    
    # è¯„ä¼°é…ç½®
    eval_workers: int = 100  # è¯„ä¼°å¹¶è¡Œæ•°ï¼ˆé»˜è®¤100ï¼‰
    eval_remove_role_thinking: bool = False  # æ¶ˆèå®éªŒï¼šè¯„ä¼°æ—¶æ˜¯å¦ç§»é™¤ role_thinking
    dimensions: List[str] = field(default_factory=lambda: [
        'Storyline Consistency',
        'Anthropomorphism', 
        'Character Fidelity',
        'Storyline Quality'
    ])
    
    # æ¨¡å‹ç±»å‹: coser, her, qwen, llama3, api
    model_type: str = "her"


class CharacterAgent:
    """è§’è‰² Agent - ç®¡ç†å•ä¸ªè§’è‰²çš„å¯¹è¯å†å²
    
    æ”¯æŒä¸åŒæ¨¡å‹ç±»å‹çš„å¯¹è¯æ ¼å¼å¤„ç†
    """
    
    def __init__(
        self,
        name: str,
        model: Any,
        system_prompt: str,
        model_type: str = "her"
    ):
        self.name = name
        self.model = model
        self.system_prompt = system_prompt
        self.model_type = model_type
        self.messages: List[Dict[str, str]] = [
            {"role": "system", "content": system_prompt}
        ]
        
        full_log_print(f"è§’è‰²: {name}", "ğŸ‘¤")
        full_log_print(f"æ¨¡å‹ç±»å‹: {model_type}", "ğŸ¤–")
        full_log_print(f"System Prompt:\n{'='*60}\n{system_prompt}\n{'='*60}", "ğŸ“")
    
    def update(self, role: str, content: str, name: Optional[str] = None):
        """æ›´æ–°å¯¹è¯å†å²"""
        msg = {"role": role, "content": content}
        if name:
            msg["name"] = name
        self.messages.append(msg)
        
        full_log_print(f"[{self.name}] æ·»åŠ æ¶ˆæ¯: role={role}, name={name}", "ğŸ’¬")
        full_log_print(f"å†…å®¹: {content[:200]}..." if len(content) > 200 else f"å†…å®¹: {content}", "ğŸ“„")
    
    async def chat(self, max_tokens: int = 4096, temperature: float = 0.7, round_num: int = 0) -> str:
        """ç”Ÿæˆå›å¤
        
        æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ä¸åŒçš„è°ƒç”¨æ–¹å¼ï¼š
        - her: ä½¿ç”¨ completions API + Qwen chat template
        - å…¶ä»–: ä½¿ç”¨ chat completions API
        
        Args:
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            temperature: æ¸©åº¦å‚æ•°
            round_num: å½“å‰è½®æ¬¡ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        """
        try:
            # ğŸ“¨ æ‰“å°å®Œæ•´çš„ OpenAI æ ¼å¼ JSON æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆä¸æˆªæ–­ï¼‰
            if FULL_LOG:
                log_messages_json(self.messages, self.name, round_num)
            
            if self.model_type == 'her':
                # HER æ¨¡å‹ä½¿ç”¨ completions API + Qwen chat template
                # è¿™æ ·æ‰èƒ½æ­£ç¡®è¾“å‡º <system_think> æ ‡ç­¾
                prompt = apply_qwen_chat_template(self.messages)
                
                # ğŸ“¤ æ‰“å° ChatTemplate ä¹‹å (HER æ ¼å¼)
                if FULL_LOG:
                    # å•è¡Œæ ¼å¼ (æ–¹ä¾¿å¤åˆ¶æµ‹è¯•)
                    prompt_oneline = repr(prompt)
                    print(f"\n[LOG:TEMPLATE] [{self.name}] HER æ ¼å¼")
                    print(f"{LOG_SEP}")
                    print(f"ğŸ“¤ [{self.name}] ChatTemplate ä¹‹å (HER completions API) - å•è¡Œæ ¼å¼")
                    print(LOG_SEP)
                    print(prompt_oneline)
                    print(LOG_SEP)
                    # å¤šè¡Œæ ¼å¼ (æ–¹ä¾¿é˜…è¯»)
                    print(f"\nğŸ“¤ [{self.name}] ChatTemplate ä¹‹å (HER completions API) - å¤šè¡Œæ ¼å¼")
                    print(LOG_SEP)
                    print(prompt)
                    print(LOG_SEP)
                
                # HER æ¨¡å‹ä½¿ç”¨ complete æ–¹æ³• - ä¼˜å…ˆç”¨å¼‚æ­¥ç‰ˆæœ¬
                if hasattr(self.model, 'complete_async'):
                    response = await self.model.complete_async(
                        prompt=prompt,
                        max_tokens=max_tokens,
                        temperature=temperature,
                        stop=get_stop_tokens('her')
                    )
                elif hasattr(self.model, 'complete'):
                    # åŒæ­¥ç‰ˆæœ¬ç”¨ asyncio.to_thread åŒ…è£…
                    response = await asyncio.to_thread(
                        self.model.complete,
                        prompt=prompt,
                        max_tokens=max_tokens,
                        temperature=temperature,
                        stop=get_stop_tokens('her')
                    )
                else:
                    logger.warning(f"Model doesn't have complete method, falling back to chat")
                    response = await asyncio.to_thread(
                        self.model.chat,
                        messages=self.messages,
                        max_tokens=max_tokens,
                        temperature=temperature
                    )
            else:
                # å…¶ä»–æ¨¡å‹ä½¿ç”¨ chat API
                if FULL_LOG:
                    import json
                    print(f"\n{LOG_SEP}")
                    print(f"ğŸ“¤ [{self.name}] å‘é€ç»™ API çš„è¯·æ±‚ (chat API)")
                    print(LOG_SEP)
                    print(f"æ¨¡å‹ç±»å‹: {self.model_type}")
                    print(f"æ¶ˆæ¯æ•°é‡: {len(self.messages)}")
                    print(f"\nå®Œæ•´ messages JSON:")
                    print(json.dumps(self.messages, ensure_ascii=False, indent=2))
                    print(LOG_SEP)
                
                # æ ‡å‡† chat æ¥å£ï¼ˆåŒæ­¥è°ƒç”¨ï¼Œç”¨ asyncio.to_thread åŒ…è£…ï¼‰
                response = await asyncio.to_thread(
                    self.model.chat,
                    messages=self.messages,
                    max_tokens=max_tokens,
                    temperature=temperature
                )
            
            # ğŸ“¥ æ‰“å° Raw Response - å®Œæ•´æ‰“å°
            if FULL_LOG:
                print(f"\n[LOG:RESPONSE] [{self.name}]")
                print(f"{LOG_SEP}")
                print(f"ğŸ“¥ [{self.name}] Raw Response (å®Œæ•´)")
                print(LOG_SEP)
                print(response or "(ç©ºå“åº”)")
                print(LOG_SEP)
            
            return response or ""
        except Exception as e:
            logger.error(f"Agent {self.name} chat error: {e}")
            if FULL_LOG:
                import traceback
                print(f"âŒ [{self.name}] é”™è¯¯è¯¦æƒ…:")
                traceback.print_exc()
            return ""


class CoSERBenchmark(MultiTurnBenchmark):
    """CoSER Benchmark å®ç°
    
    Given-Circumstance Acting (GCA) è¯„æµ‹ï¼š
    - å¤šè§’è‰²åŒæ—¶å¯¹è¯
    - ç¯å¢ƒ Agent æä¾›åœºæ™¯åé¦ˆ
    - NSP Agent é¢„æµ‹ä¸‹ä¸€è¯´è¯è€…
    - å››ç»´åº¦ LLM Judge è¯„ä¼°
    """
    
    name = "coser"
    
    def __init__(self, config: CoSERConfig):
        # å…ˆè®¾ç½®é…ç½®ï¼Œå†è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        self.coser_config = config
        super().__init__(config)
    
    def _load_data(self) -> List[Dict[str, Any]]:
        """åŠ è½½ CoSER æµ‹è¯•æ•°æ®"""
        data_path = Path(self.config.data_path)
        
        if not data_path.exists():
            raise FileNotFoundError(f"Data file not found: {data_path}")
        
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        logger.info(f"Loaded {len(data)} CoSER test cases")
        return data
    
    def get_sample_id(self, sample: Dict[str, Any], index: int) -> str:
        """è·å–æ ·æœ¬å”¯ä¸€æ ‡è¯†"""
        book = sample.get('book', 'unknown')
        i_p = sample.get('plot', {}).get('i_p', index)
        i_c = sample.get('i_c', 0)
        return f"{book}-{i_p}-{i_c}"
    
    async def run_inference_single(
        self,
        sample: Dict[str, Any],
        model: Any,
        env_model: Optional[Any] = None,
        nsp_model: Optional[Any] = None,
        **kwargs
    ) -> InferenceResult:
        """
        å¯¹å•ä¸ªæ ·æœ¬è¿›è¡Œ GCA æ¨¡æ‹Ÿ
        
        Args:
            sample: æµ‹è¯•æ ·æœ¬
            model: Actor æ¨¡å‹ï¼ˆè§’è‰²æ‰®æ¼”ï¼‰
            env_model: ç¯å¢ƒæ¨¡å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨åŒä¸€æ¨¡å‹ï¼‰
            nsp_model: NSP æ¨¡å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨åŒä¸€æ¨¡å‹ï¼‰
        """
        sample_id = self.get_sample_id(sample, 0)
        logger.info(f"Starting GCA simulation for {sample_id}")
        
        # ä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹æˆ–å›é€€åˆ°ä¸»æ¨¡å‹
        env_model = env_model or model
        nsp_model = nsp_model or model
        
        # è·å–æ¨¡å‹ç±»å‹
        model_type = self.coser_config.model_type
        if not model_type:
            model_type = get_model_type(self.coser_config.actor_model)
        
        full_log_print(f"æ¨¡å‹ç±»å‹: {model_type}", "ğŸ”§")
        
        # æå–åœºæ™¯ä¿¡æ¯
        book_title = sample.get('book', 'Unknown')
        plot = sample.get('plot', {})
        character_profiles = sample.get('character_profiles', {})
        scenario = sample.get('scenario', '')
        speaking_characters = sample.get('speaking_characters_w_env', [])
        major_characters = sample.get('major_characters', [])
        
        # ç¡®ä¿ Environment åœ¨è§’è‰²åˆ—è¡¨ä¸­
        if ENVIRONMENT not in speaking_characters:
            speaking_characters.append(ENVIRONMENT)
        
        # æ„å»ºå¢å¼ºçš„è§’è‰²æ¡£æ¡ˆ
        involved_profiles = {}
        plot_characters = [c['name'] for c in plot.get('key_characters', [])]
        
        for character in speaking_characters:
            if character == ENVIRONMENT:
                continue
            
            profile = character_profiles.get(character, '')
            if character in plot_characters:
                char_info = next(
                    (c for c in plot.get('key_characters', []) if c.get('name') == character),
                    {}
                )
                if 'description' in char_info:
                    profile = char_info['description'].strip() + '\n\n' + profile.strip()
            
            if profile.strip():
                involved_profiles[character] = profile.strip()
        
        # åˆ›å»ºæ‰€æœ‰ Agent
        agents = {}
        
        for character in speaking_characters + [NSP]:
            if character == NSP:
                # NSP Agent - ä½¿ç”¨æ ‡å‡†æ ¼å¼
                system_prompt = get_nsp_prompt(speaking_characters, scenario)
                agent_model = nsp_model
                agent_model_type = "her"  # NSP æ€»æ˜¯ç”¨æ ‡å‡†æ ¼å¼
            elif character == ENVIRONMENT:
                # Environment Agent - ä½¿ç”¨æ ‡å‡†æ ¼å¼
                system_prompt = get_environment_prompt(major_characters, scenario)
                agent_model = env_model
                agent_model_type = "her"  # ç¯å¢ƒæ€»æ˜¯ç”¨æ ‡å‡†æ ¼å¼
            else:
                # Character Agent - ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹ç±»å‹
                char_profile = involved_profiles.get(character, '')
                
                # è·å–è§’è‰²åŠ¨æœº
                motivation = ''
                key_chars = sample.get('key_characters', [])
                for c in key_chars:
                    if c.get('name') == character:
                        motivation = c.get('motivation', '')
                        break
                
                # CoSER æ¨¡å‹ä¸éœ€è¦è¾“å‡ºç¤ºä¾‹
                add_output_example = model_type not in ['coser']
                
                system_prompt = get_character_prompt(
                    book_name=book_title,
                    character=character,
                    character_profile=char_profile,
                    background=plot.get('summary', ''),
                    scenario=scenario,
                    motivation=motivation,
                    thoughtless=self.coser_config.wo_thought,
                    other_character_profiles=involved_profiles,
                    model_type=model_type,
                    add_output_example=add_output_example
                )
                agent_model = model
                agent_model_type = model_type
            
            agent = CharacterAgent(
                name=character,
                model=agent_model,
                system_prompt=system_prompt,
                model_type=agent_model_type
            )
            agent.update('user', "===Conversation Start===\n\n")
            agents[character] = agent
        
        # å¼€å§‹å¯¹è¯æ¨¡æ‹Ÿ
        dialogue = []
        current_speaker = speaking_characters[0]
        ground_truth = sample.get('dialogues', [])
        max_rounds = self.coser_config.max_rounds
        continue_from = self.coser_config.continue_from
        
        for i_round in range(max_rounds):
            if current_speaker == "<END CHAT>":
                break
            
            # ğŸ­ è½®æ¬¡å¼€å§‹æ—¥å¿—
            logger.info(f"===Round {i_round + 1}=== Speaker: {current_speaker}")
            if FULL_LOG:
                print(f"\n{'ğŸ­'*20}")
                print(f"ğŸ­ ç¬¬ {i_round + 1} è½® | å½“å‰è¯´è¯è€…: {current_speaker}")
                print(f"{'ğŸ­'*20}")
            
            # ç”Ÿæˆå½“å‰è¯´è¯è€…çš„å›å¤
            for actor in [current_speaker, NSP]:
                agent = agents[actor]
                
                # âš¡ ä¼˜åŒ–ï¼šNSP randomæ¨¡å¼ç›´æ¥è·³è¿‡æ¨¡å‹è°ƒç”¨
                if actor == NSP and self.coser_config.nsp_mode == "random" and continue_from <= i_round:
                    response = None  # randomæ¨¡å¼ä¸éœ€è¦æ¨¡å‹å“åº”
                # ä½¿ç”¨ ground truth æˆ–æ¨¡å‹ç”Ÿæˆ
                elif continue_from > i_round:
                    if actor == current_speaker:
                        response = ground_truth[i_round]['message'] if i_round < len(ground_truth) else ""
                    else:  # NSP
                        next_char = ground_truth[i_round + 1]['character'] if i_round + 1 < len(ground_truth) else "<END CHAT>"
                        response = next_char
                else:
                    response = await agent.chat(
                        max_tokens=self.config.max_tokens,
                        temperature=self.config.temperature,
                        round_num=i_round + 1
                    )
                
                if actor == NSP:
                    # è·å– NSP æ¨¡å¼
                    nsp_mode = self.coser_config.nsp_mode
                    
                    # ğŸ² NSP æ¨¡å¼: random - ç›´æ¥éšæœºé€‰æ‹©ï¼Œä¸è°ƒç”¨æ¨¡å‹
                    if nsp_mode == "random":
                        # æ’é™¤å½“å‰è¯´è¯è€…ã€Environmentã€Narrator
                        excluded = {current_speaker, ENVIRONMENT, "Narrator", "narrator"}
                        available_chars = [c for c in speaking_characters if c not in excluded]
                        if not available_chars:
                            available_chars = [c for c in speaking_characters if c != current_speaker]
                        
                        if available_chars:
                            next_actor = random.choice(available_chars)
                            current_speaker = next_actor
                        else:
                            next_actor = "<END CHAT>"
                            current_speaker = "<END CHAT>"
                        
                        # ğŸ“Š NSP è¯¦ç»†æ—¥å¿— (Random æ¨¡å¼)
                        if FULL_LOG:
                            print(f"\n{LOG_SEP_THIN}")
                            print(f"ğŸ² NSP (Random æ¨¡å¼)")
                            print(LOG_SEP_THIN)
                            print(f"   å€™é€‰è§’è‰²: {available_chars}")
                            print(f"   æ’é™¤è§’è‰²: {excluded}")
                            print(f"   âœ… æœ€ç»ˆé€‰æ‹©: {next_actor}")
                            print(LOG_SEP_THIN)
                        
                        logger.info(f"Next speaker (random): {current_speaker}")
                        
                        dialogue.append({
                            "role": NSP,
                            "content": next_actor,
                            "round": i_round
                        })
                        agent.update('assistant', next_actor)
                    else:
                        # ğŸ¤– NSP æ¨¡å¼: model - ä½¿ç”¨æ¨¡å‹é¢„æµ‹
                        raw_nsp_response = response
                        next_actor = parse_nsp_response(response, speaking_characters)
                        
                        # ç®€åŒ–é€»è¾‘ï¼šåªæœ‰åœ¨æœ‰æ•ˆä¸”éé‡å¤æ—¶æ‰é‡‡ç”¨ï¼Œå¦åˆ™ä¸€å¾‹éšæœº
                        final_speaker = None
                        fallback_reason = None
                        
                        if next_actor == "<END CHAT>" and i_round >= 5:
                            final_speaker = "<END CHAT>"
                        elif next_actor in speaking_characters and next_actor != current_speaker:
                            # æœ‰æ•ˆè§’è‰²ä¸”ä¸é‡å¤ï¼Œé‡‡ç”¨ NSP ç»“æœ
                            final_speaker = next_actor
                        else:
                            # æ ¼å¼ä¸å¯¹ / é‡å¤ä¸Šä¸€è½®è§’è‰² / æœªçŸ¥è§’è‰² -> éšæœºé€‰æ‹©éä¸Šä¸€è½®è§’è‰²
                            candidates = set(major_characters + [ENVIRONMENT]) - {current_speaker}
                            if not candidates:
                                candidates = set(speaking_characters) - {current_speaker}
                            old_speaker = current_speaker
                            final_speaker = random.choice(list(candidates)) if candidates else "<END CHAT>"
                            fallback_reason = f"NSP é€‰æ‹©äº† '{next_actor}'ï¼Œä½†æ— æ•ˆ/é‡å¤ï¼Œä» {candidates} éšæœºé€‰æ‹©"
                            logger.info(f"âš ï¸ NSP ä»é€‰æ‹©äº†ä¸Šä¸€ä¸ªè¯´è¯è€… {old_speaker}ï¼Œresponse: {response[:100]}")
                        
                        current_speaker = final_speaker
                        
                        # ğŸ“Š NSP è¯¦ç»†æ—¥å¿— (Model æ¨¡å¼)
                        if FULL_LOG:
                            print(f"\n[LOG:NSP] Model æ¨¡å¼")
                            print(f"{LOG_SEP_THIN}")
                            print(f"ğŸ¤– NSP (Model æ¨¡å¼)")
                            print(LOG_SEP_THIN)
                            print(f"   Raw Response (å®Œæ•´):")
                            print(f"   {raw_nsp_response}")
                            print(f"   ---")
                            print(f"   è§£æç»“æœ: {next_actor}")
                            print(f"   æœ‰æ•ˆè§’è‰²åˆ—è¡¨: {speaking_characters}")
                            if fallback_reason:
                                print(f"   âš ï¸ å›é€€åŸå› : {fallback_reason}")
                            print(f"   âœ… æœ€ç»ˆé€‰æ‹©: {final_speaker}")
                            print(LOG_SEP_THIN)
                        
                        logger.info(f"Next speaker: {current_speaker} (Raw NSP: {next_actor})")
                        
                        dialogue.append({
                            "role": NSP,
                            "content": next_actor,
                            "round": i_round
                        })
                        agent.update('assistant', next_actor)
                else:
                    # è§’è‰²/ç¯å¢ƒå›å¤
                    is_environment = (actor == ENVIRONMENT)
                    
                    # ğŸ“Š è§’è‰²/ç¯å¢ƒå›å¤è¯¦ç»†æ—¥å¿—
                    if FULL_LOG:
                        role_type = "ğŸŒ Environment" if is_environment else f"ğŸ‘¤ {actor}"
                        print(f"\n{LOG_SEP_THIN}")
                        print(f"{role_type} å›å¤å¤„ç† (ç¬¬ {i_round + 1} è½®)")
                        print(LOG_SEP_THIN)
                        print(f"[1] Raw Response (å®Œæ•´):")
                        print(response)  # å®Œæ•´æ‰“å°ï¼Œä¸æˆªæ–­
                    
                    # Environment å“åº”éœ€è¦ç§»é™¤ <think> æ ‡ç­¾
                    if is_environment:
                        response = remove_system_thinking(response)
                        if FULL_LOG:
                            print(f"\n[1.5] Environment ç§»é™¤ <think> å:")
                            print(response)
                    
                    dialogue_entry = {
                        "role": actor,
                        "content": response,
                        "round": i_round
                    }
                    dialogue.append(dialogue_entry)
                    
                    # ğŸ“Š æ‰“å°æ·»åŠ åˆ° dialogue çš„ JSON
                    if FULL_LOG:
                        print(f"\n[ğŸ“‹ æ·»åŠ åˆ° dialogue çš„æ¶ˆæ¯]")
                        print(json.dumps(dialogue_entry, ensure_ascii=False, indent=2))
                    
                    # æ¸…ç†å›å¤ç”¨äºæ›´æ–°å…¶ä»– agent çš„å†å²
                    # 1. å…ˆå¤„ç† long_role_thinking
                    response_clean = remove_long_role_thinking(response)
                    # 2. ç§»é™¤ system_thinking (ä¿ç•™ role_thinking!)
                    response_clean = remove_system_thinking(response_clean)
                    
                    if FULL_LOG:
                        print(f"\n[2] ç§»é™¤ system_thinking å (ä¿ç•™ role_thinking):")
                        print(response_clean)  # å®Œæ•´æ‰“å°
                    
                    # æ™®é€šæ¨¡å‹éœ€è¦åŠ è§’è‰²åå‰ç¼€
                    response_clean = add_speaker_name(response_clean, actor)
                    if FULL_LOG:
                        print(f"\n[3] æ·»åŠ è¯´è¯è€…å‰ç¼€å:")
                        print(response_clean)  # å®Œæ•´æ‰“å°
                    
                    # æ›´æ–°æ‰€æœ‰ agent çš„å¯¹è¯å†å²
                    if FULL_LOG:
                        print(f"\n[4] æ›´æ–°å„ Agent çš„å¯¹è¯å†å²:")
                    
                    for other_actor, other_agent in agents.items():
                        if other_actor == actor:
                            # ç»™è‡ªå·±ï¼šä¿ç•™å®Œæ•´å†…å®¹ï¼ˆåŒ…æ‹¬ system_thinking å’Œ role_thinkingï¼‰
                            # è®­ç»ƒæ—¶æ¨¡å‹èƒ½çœ‹åˆ°è‡ªå·±ä¹‹å‰çš„å®Œæ•´è¾“å‡ºï¼Œæµ‹è¯•æ—¶ä¹Ÿè¦ä¿æŒä¸€è‡´
                            response_for_self = response
                            if FULL_LOG:
                                has_system_think = '<system_think>' in response_for_self or '<system_thinking>' in response_for_self
                                print(f"    ğŸ‘¤ ç»™è‡ªå·± ({actor}): ä¿ç•™å®Œæ•´å†…å®¹ (å« system_think: {has_system_think})")
                                print(f"       å†…å®¹å‰100å­—: {response_for_self[:100]}...")
                            other_agent.update('assistant', response_for_self, name=actor)
                        else:
                            # ç»™åˆ«äººï¼šç§»é™¤æ‰€æœ‰å†…å¿ƒæƒ³æ³•ï¼ˆ<role_thinking> å’Œ [...]ï¼‰ï¼Œä¿ç•™åŠ¨ä½œæ ¼å¼
                            response_for_others = remove_inner_thoughts(response_clean)
                            if FULL_LOG:
                                print(f"    ğŸ‘¥ ç»™ {other_actor}: ç§»é™¤ role_thinking ->")
                                print(f"       {response_for_others}")  # å®Œæ•´æ‰“å°
                            other_agent.update('user', response_for_others, name=actor)
                    
                    if FULL_LOG:
                        print(LOG_SEP_THIN)
        
        # æ‰“å°å®Œæ•´å¯¹è¯è®°å½•
        if FULL_LOG:
            print(f"\n{'='*60}")
            print(f"ğŸ“Š åœºæ™¯å®Œæ•´å¯¹è¯è®°å½•: {book_title} (å…± {len(dialogue)} æ¡æ¶ˆæ¯)")
            print(f"{'='*60}")
            for i, conv in enumerate(dialogue):
                print(f"\n[{i+1}] {conv['role']} (è½®æ¬¡: {conv.get('round', 'N/A')}):")
                print(conv['content'])  # å®Œæ•´æ‰“å°
            print(f"\n{'='*60}\n")
        
        return InferenceResult(
            sample_id=sample_id,
            model_name=self.coser_config.actor_model,
            input_data=sample,
            dialogue=dialogue,
            metadata={
                "book_title": book_title,
                "i_p": plot.get('i_p'),
                "i_c": sample.get('i_c'),
                "involved_character_profiles": involved_profiles,
                "total_rounds": len([d for d in dialogue if d['role'] != NSP]),
                "model_type": model_type
            },
            status="completed"
        )
    
    async def evaluate_single(
        self,
        inference_result: InferenceResult,
        judge_model: Optional[Any] = None,
        **kwargs
    ) -> EvaluationResult:
        """
        è¯„ä¼°å•æ¡æ¨ç†ç»“æœ
        
        ä½¿ç”¨ LLM-as-Judge è¿›è¡Œå››ç»´åº¦è¯„ä¼°ï¼š
        1. Storyline Consistency - æ•…äº‹çº¿ä¸€è‡´æ€§
        2. Anthropomorphism - æ‹ŸäººåŒ–
        3. Character Fidelity - è§’è‰²å¿ å®åº¦
        4. Storyline Quality - æ•…äº‹çº¿è´¨é‡
        """
        sample_id = inference_result.sample_id
        sample = inference_result.input_data
        simulation = inference_result.dialogue
        metadata = inference_result.metadata
        model_type = metadata.get('model_type', 'her')
        
        logger.info(f"Evaluating {sample_id}")
        
        # è¿‡æ»¤ NSP æ¶ˆæ¯ï¼Œå‡†å¤‡è¯„ä¼°æ•°æ®
        simulation_filtered = [m for m in simulation if m['role'] != NSP]
        reference = sample.get('dialogues', [])
        
        # æ¸…ç† simulation å¹¶ç»Ÿä¸€è½¬æ¢ä¸º CoSER æ ¼å¼ç”¨äºè¯„ä¼°
        # 1. ç§»é™¤ system_thinking
        # 2. å°†æ‰€æœ‰æ ¼å¼ç»Ÿä¸€è½¬æ¢ä¸º CoSER æ ¼å¼:
        #    - HER: <role_thinking> -> [...], <role_action> -> (...)
        #    - CoSER: ä¿æŒä¸å˜
        simulation_for_eval = []
        for m in simulation_filtered:
            if m['role'] == ENVIRONMENT:
                simulation_for_eval.append(m)
            else:
                # å…ˆç§»é™¤ system_thinking
                cleaned_content = remove_system_thinking(m['content'])
                # æ¶ˆèå®éªŒï¼šå…ˆç§»é™¤ role_thinkingï¼ˆå¿…é¡»åœ¨æ ¼å¼è½¬æ¢ä¹‹å‰ï¼ï¼‰
                if self.coser_config.eval_remove_role_thinking:
                    cleaned_content = remove_role_thinking(cleaned_content)
                # å†ç»Ÿä¸€è½¬æ¢ä¸º CoSER æ ¼å¼
                cleaned_content = convert_to_coser_format(cleaned_content, model_type)
                simulation_for_eval.append({**m, 'content': cleaned_content})
        
        # æ—¥å¿—è®°å½•æ¶ˆèé…ç½®
        ablation_mode = "ç§»é™¤role_thinking" if self.coser_config.eval_remove_role_thinking else "ä¿ç•™role_thinking"
        logger.info(f"ğŸ“ è¯„ä¼°æ ¼å¼è½¬æ¢: {model_type} -> CoSER æ ¼å¼ ({ablation_mode})")
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç”¨äºè¯„ä¼°
        # æ‰€æœ‰æ¨¡å‹çš„ content å·²ç»æœ‰è§’è‰²åå‰ç¼€äº†ï¼Œä¸éœ€è¦é‡å¤æ·»åŠ 
        simulation_str = '\n\n'.join([
            m['content'].strip() 
            for m in simulation_for_eval
        ])
        
        # reference ä¹Ÿéœ€è¦è½¬æ¢ä¸º CoSER æ ¼å¼ï¼Œä¿æŒä¸ simulation ä¸€è‡´
        # test_set_her.json ä¸­çš„ message æ˜¯ HER æ ¼å¼ (<role_thinking>, <role_action>)
        reference_str = '\n\n'.join([
            f"{m['character']}: {convert_to_coser_format(m['message'], 'her')}".strip() 
            for m in reference
        ])
        
        logger.info(f"===Simulation of {sample_id}===\n{simulation_str[:500]}...\n")
        
        # å‡†å¤‡è¯„ä¼°ä¸Šä¸‹æ–‡
        book_title = metadata.get('book_title', 'Unknown')
        scenario = sample.get('scenario', '')
        plot_summary = sample.get('plot', {}).get('summary', '')
        involved_profiles = metadata.get('involved_character_profiles', {})
        major_characters = sample.get('major_characters', [])
        
        character_profile_str = '\n\n'.join([
            f"### {char}\n\n{profile.strip()}"
            for char, profile in involved_profiles.items()
        ])
        
        # å¹¶å‘è¯„ä¼°å››ä¸ªç»´åº¦
        dimensions = self.coser_config.dimensions
        eval_results = {}
        
        # è®¡ç®—é Environment çš„å¯¹è¯è½®æ•°ï¼ˆç”¨äºåˆ†æ•°è°ƒæ•´ï¼‰
        actor_rounds = len([m for m in simulation_for_eval if m['role'] != ENVIRONMENT])
        
        def evaluate_dimension(dimension: str) -> Tuple[str, Dict]:
            """è¯„ä¼°å•ä¸ªç»´åº¦"""
            try:
                critic_prompt = CRITIC_PROMPTS['self-play-deduct-template'].format(
                    book=book_title,
                    plot_summary=plot_summary,
                    scenario=scenario,
                    character_profiles=character_profile_str,
                    original_conversation=reference_str,
                    major_characters=', '.join(major_characters),
                    additional_instructions='',
                    dimension_name=dimension,
                    dimension_brief=CRITIC_PROMPTS['dimension_details'][dimension]['dimension_brief'],
                    dimension_criteria=CRITIC_PROMPTS['dimension_details'][dimension]['dimension_criteria']
                )
                
                # ğŸ“Š è¯„ä¼°æ—¥å¿— - è¾“å…¥
                if FULL_LOG:
                    print(f"\n[LOG:EVAL] ç»´åº¦: {dimension}")
                    print(f"{'â­'*30}")
                    print(f"â­ è¯„ä¼°ç»´åº¦: {dimension}")
                    print(f"{'â­'*30}")
                    print(f"\nğŸ“‹ Judge System Prompt (å®Œæ•´):")
                    print(critic_prompt)
                    print(f"\nğŸ“‹ Judge User Input (å¯¹è¯å†…å®¹):")
                    print(simulation_str)
                    print(f"{'â­'*30}\n")
                
                # åŒæ­¥è°ƒç”¨ judge model
                print(f"[DEBUG] judge_model={judge_model}, type={type(judge_model)}")
                if judge_model:
                    if hasattr(judge_model, 'chat_sync'):
                        response = judge_model.chat_sync(
                            messages=[
                                {"role": "system", "content": critic_prompt},
                                {"role": "user", "content": simulation_str}
                            ],
                            max_tokens=2048,
                            temperature=0
                        )
                    elif hasattr(judge_model, 'chat'):
                        # åŒæ­¥è°ƒç”¨ chat æ–¹æ³• (vLLM model çš„ chat æ˜¯åŒæ­¥çš„)
                        response = judge_model.chat(
                            messages=[
                                {"role": "system", "content": critic_prompt},
                                {"role": "user", "content": simulation_str}
                            ],
                            max_tokens=2048,
                            temperature=0
                        )
                    else:
                        # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯ (ç”¨äº ThreadPoolExecutor)
                        import asyncio
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            response = loop.run_until_complete(judge_model.achat(
                            messages=[
                                {"role": "system", "content": critic_prompt},
                                {"role": "user", "content": simulation_str}
                            ],
                            max_tokens=2048,
                            temperature=0
                        ))
                        finally:
                            loop.close()
                    
                    # ğŸ“Š è¯„ä¼°æ—¥å¿— - è¾“å‡º
                    if FULL_LOG:
                        print(f"\n{'âœ¨'*30}")
                        print(f"âœ¨ ç»´åº¦ {dimension} - Judge Raw Response:")
                        print(f"{'âœ¨'*30}")
                        print(response)
                        print(f"{'âœ¨'*30}\n")
                    
                    # è§£æ JSON å“åº”ï¼ˆå¸¦é•¿åº¦æƒ©ç½šï¼‰
                    result = self._parse_eval_response(response, dimension, actor_rounds)
                    
                    # ğŸ“Š è¯„ä¼°æ—¥å¿— - è§£æç»“æœ
                    if FULL_LOG:
                        print(f"\nğŸ“Š ç»´åº¦ {dimension} - è§£æç»“æœ:")
                        print(f"   åˆ†æ•°: {result.get('score', 0):.2f}")
                        print(f"   ç¼ºé™·æ•°: {len(result.get('flaws', []))}")
                        for i, flaw in enumerate(result.get('flaws', [])[:5]):  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                            print(f"   [{i+1}] {flaw}")
                        print()
                else:
                    result = {"flaws": [], "score": 100}
                
                logger.info(f"âœ… ç»´åº¦ {dimension} å®Œæˆï¼Œåˆ†æ•°: {result.get('score', 0):.2f}")
                return dimension, result
                
            except Exception as e:
                logger.error(f"Error evaluating {dimension}: {e}")
                return dimension, {"flaws": [], "score": 0, "error": str(e)}
        
        # å¹¶å‘æ‰§è¡Œè¯„ä¼°
        with ThreadPoolExecutor(max_workers=self.coser_config.eval_workers) as executor:
            futures = {
                executor.submit(evaluate_dimension, dim): dim 
                for dim in dimensions
            }
            
            for future in as_completed(futures):
                dim, result = future.result()
                eval_results[dim] = result
        
        logger.info(f"âœ… 4ä¸ªç»´åº¦å¹¶å‘è¯„ä¼°å®Œæˆï¼")
        
        # è®¡ç®— BLEU å’Œ ROUGE
        bleu, rouge_l = calculate_bleu_rouge(
            reference[self.coser_config.continue_from:],
            simulation_for_eval[self.coser_config.continue_from:]
        )
        
        # æ±‡æ€»åˆ†æ•°
        scores = {
            dim: eval_results[dim].get('score', 0)
            for dim in dimensions
        }
        scores['bleu'] = bleu
        scores['rouge_l'] = rouge_l
        scores['avg'] = sum(scores[d] for d in dimensions) / len(dimensions)
        
        return EvaluationResult(
            sample_id=sample_id,
            inference_result=inference_result,
            scores=scores,
            details={
                "dimension_results": eval_results,
                "simulation_str": simulation_str,
                "reference_str": reference_str
            }
        )
    
    def _parse_eval_response(self, response: str, dimension: str, actor_rounds: int = 0) -> Dict:
        """è§£æè¯„ä¼°æ¨¡å‹çš„ JSON å“åº”
        
        åˆ†æ•°è®¡ç®—å…¬å¼ï¼ˆå‚è€ƒåŸå§‹ CoSER ä»£ç ï¼‰:
        score = max(0, min(100 - (total_severity - 0.3 * actor_rounds) * 5, 100))
        
        é•¿åº¦æƒ©ç½šï¼šå¯¹è¯è½®æ•°è¶Šå¤šï¼Œå…è®¸çš„ç¼ºé™·å®¹å¿åº¦è¶Šé«˜
        """
        import re
        
        try:
            # å°è¯•æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                data = json.loads(json_match.group())
                
                if dimension in data:
                    result = data[dimension]
                    flaws = result.get('flaws', [])
                    
                    # è®¡ç®—åˆ†æ•°ï¼ˆæ‰£åˆ†åˆ¶ï¼Œå¸¦é•¿åº¦æƒ©ç½šï¼‰
                    # åŸå§‹å…¬å¼: score = max(0, min(100 - (total_severity - 0.3 * actor_rounds) * 5, 100))
                    total_severity = sum(
                        f.get('severity', 1)
                        for f in flaws 
                        if isinstance(f.get('severity'), (int, float))
                    )
                    # é•¿åº¦æƒ©ç½šï¼šå¯¹è¯è½®æ•°è¶Šå¤šï¼Œå…è®¸çš„ç¼ºé™·å®¹å¿åº¦è¶Šé«˜
                    adjusted_severity = total_severity - 0.3 * actor_rounds
                    score = max(0, min(100 - adjusted_severity * 5, 100))
                    result['score'] = score
                    
                    return result
        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse JSON: {e}")
        
        return {"flaws": [], "score": 50}  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
    
    async def run_full_evaluation(
        self,
        actor_model: Any,
        model_name: str,
        env_model: Optional[Any] = None,
        nsp_model: Optional[Any] = None,
        judge_model: Optional[Any] = None,
        mode: str = "full",
        inference_dir: Optional[str] = None,
        limit: Optional[int] = None,
        skip_cache: bool = False,
        model_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„ CoSER è¯„ä¼°æµç¨‹
        
        Args:
            actor_model: è§’è‰²æ‰®æ¼”æ¨¡å‹
            model_name: æ¨¡å‹åç§°
            env_model: ç¯å¢ƒæ¨¡å‹
            nsp_model: NSP æ¨¡å‹
            judge_model: è¯„ä¼°æ¨¡å‹
            mode: è¿è¡Œæ¨¡å¼ ("full", "inference", "evaluate")
            inference_dir: è¯„ä¼°æ¨¡å¼ä¸‹çš„æ¨ç†ç»“æœç›®å½•
            limit: é™åˆ¶æ ·æœ¬æ•°é‡
            skip_cache: æ˜¯å¦è·³è¿‡ç¼“å­˜
            model_type: å¼ºåˆ¶æŒ‡å®šæ¨¡å‹ç±»å‹ (coser, her, qwen, llama3, api)
        
        Returns:
            è¯„ä¼°ç»“æœ
        """
        # æ›´æ–°é…ç½®
        self.coser_config.actor_model = model_name
        
        # è®¾ç½®æ¨¡å‹ç±»å‹
        if model_type:
            self.coser_config.model_type = model_type
        elif not self.coser_config.model_type:
            self.coser_config.model_type = get_model_type(model_name)
        
        logger.info(f"Model type: {self.coser_config.model_type}")
        
        result = {
            "benchmark": self.name,
            "model": model_name,
            "model_type": self.coser_config.model_type,
            "mode": mode,
            "timestamp": datetime.now().isoformat()
        }
        
        # æ¨ç†é˜¶æ®µ
        if mode in ["full", "inference"]:
            inference_results = await self.run_inference(
                model=actor_model,
                model_name=model_name,
                limit=limit,
                skip_cache=skip_cache,
                env_model=env_model,
                nsp_model=nsp_model
            )
            result["inference"] = {
                "total": len(inference_results),
                "completed": len([r for r in inference_results if r.status == "completed"]),
                "failed": len([r for r in inference_results if r.status == "failed"])
            }
        else:
            inference_results = None
        
        # è¯„ä¼°é˜¶æ®µ
        if mode in ["full", "evaluate"]:
            eval_results, summary = await self.run_evaluation(
                inference_results=inference_results,
                inference_dir=inference_dir,
                judge_model=judge_model,
                skip_cache=skip_cache
            )
            result["evaluation"] = summary
        
        return result
